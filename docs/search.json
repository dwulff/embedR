[{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Dirk U. Wulff. Author, maintainer. Samuel Aeschbach. Contributor. Zak Hussain. Contributor. Rui Mata. Contributor.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Wulff DU (2023). embedR: Embed analyze text. R package version 0.1.0, https://CRAN.R-project.org/package=embedR.","code":"@Manual{,   title = {embedR: Embed and analyze text},   author = {Dirk U. Wulff},   year = {2023},   note = {R package version 0.1.0},   url = {https://CRAN.R-project.org/package=embedR}, }"},{"path":"/index.html","id":"embedr","dir":"","previous_headings":"","what":"Embed and analyze text","title":"Embed and analyze text","text":"embedR package open-source R package generate analyze text embeddings. gives access open paid APIs Hugging Face, OpenAI, Cohere gnerate text embeddings offers methods group, project, relabel, visualize .","code":""},{"path":"/index.html","id":"general-information","dir":"","previous_headings":"","what":"General Information","title":"Embed and analyze text","text":"embedR package developed Dirk U. Wulff, contributions Samuel Aeschbach, Zak Hussain, Rui Mata. published GNU General Public License. overview package can accessed online within R using ?embedR.","code":""},{"path":"/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Embed and analyze text","text":"latest development version GitHub can installed via devtools::install_github(\"dwulff/embedR\"). Note requires prior installation devtools package.","code":""},{"path":"/index.html","id":"caution","dir":"","previous_headings":"","what":"Caution","title":"Embed and analyze text","text":"Use package can result data protection violations. package contains functions send data servers external APIs providers, including Hugging Face, OpenAI, Cohere.","code":""},{"path":"/index.html","id":"usage","dir":"","previous_headings":"","what":"Usage","title":"Embed and analyze text","text":"","code":"# load package library(embedR)  # vector of texts texts = c(\"This is text 1\", \"This is text 2\", ...)  # set api tokens er_set_token(\"openai\" = \"TOKEN\",              \"huggingface\" = \"TOKEN\",              \"cohere\" = \"TOKEN\")  # generate embedding embedding = texts %>%     # generate text embedding   er_embed(api = \"openai\")   # analyze embedding   result = embedding %>%     # group similar texts   er_group(method = \"fuzzy\") %>%       # generate 2D projection   er_project(method = \"umap\") %>%       # cluster projection   er_cluster(method = \"louvain\") %>%       # produce data frame   er_frame()    # re-label text groups result = embedding %>%     # relabel groups   er_mutate(labels = label(group_texts,                             api = \"openai\"))                          # visualize result %>% plot()"},{"path":"/index.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Embed and analyze text","text":"added.","code":""},{"path":"/reference/ai.html","id":null,"dir":"Reference","previous_headings":"","what":"AI association data — ai","title":"AI association data — ai","text":"Excerpt data Scharowski, Mata, Wulff (2024) containing laypeople associations artificial intelligence.","code":""},{"path":"/reference/ai.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"AI association data — ai","text":"","code":"ai"},{"path":"/reference/ai.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"AI association data — ai","text":"tibble 2,500 AI-associations following columns: id Participant id trial Index response. Every participant produced five associations. text Text responses.","code":""},{"path":"/reference/ai.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"AI association data — ai","text":"Scharowski, S., Mata, R., Wulff, D. U. (2024). Laypeople's associations AI. preparation.","code":""},{"path":"/reference/compare_embeddings.html","id":null,"dir":"Reference","previous_headings":"","what":"Compare embeddings — compare_embeddings","title":"Compare embeddings — compare_embeddings","text":"compare_embeddings computes similarity two embeddings.","code":""},{"path":"/reference/compare_embeddings.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compare embeddings — compare_embeddings","text":"","code":"compare_embeddings(   embeddings,   metric = \"cosine\",   comparison_metric = \"spearman\" )"},{"path":"/reference/compare_embeddings.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compare embeddings — compare_embeddings","text":"embeddings list embedding matrices. metric character string specifying type similarity used produce similarity matrices embedding. One c(\"cosine\",\"arccos\",\"pearson\",\"spearman\"). Default \"cosine\". comparison_metric character string specifying type similarity used compare similarity matrices. One c(\"cosine\",\"arccos\",\"pearson\",\"spearman\"). Default \"spearman\".","code":""},{"path":"/reference/compare_embeddings.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compare embeddings — compare_embeddings","text":"function returns tibble containing representational similarities every pair embeddings overall (based lower triangle) per row.","code":""},{"path":"/reference/compare_embeddings.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Compare embeddings — compare_embeddings","text":"Wulff, D. U., Aeschbach, S., & Mata, R. (2024). embeddeR. psyArXiv","code":""},{"path":"/reference/compare_embeddings.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compare embeddings — compare_embeddings","text":"","code":"# get embedding embedding_1 <- embed(neo$text) #> Error in embed(neo$text): No API tokens exist. Set at least one token with set_tokens(). See ?set_tokens embedding_2 <- embed(neo$text, model = \"distilbert-base-uncased\") #> Error in embed(neo$text, model = \"distilbert-base-uncased\"): No API tokens exist. Set at least one token with set_tokens(). See ?set_tokens  # compute similarity compare_embeddings(list(embedding_1, embedding_2)) #> Error in eval(expr, envir, enclos): object 'embedding_1' not found"},{"path":"/reference/compare_vectors.html","id":null,"dir":"Reference","previous_headings":"","what":"Compare embedding vectors — compare_vectors","title":"Compare embedding vectors — compare_vectors","text":"compare computes similarities embedding vectors.","code":""},{"path":"/reference/compare_vectors.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compare embedding vectors — compare_vectors","text":"","code":"compare_vectors(embedding, metric = \"cosine\")"},{"path":"/reference/compare_vectors.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compare embedding vectors — compare_vectors","text":"embedding numeric matrix containing text embedding. metric character string specifying type similarity. One c(\"cosine\",\"arccos\",\"pearson\",\"spearman\"). Default \"cosine\".","code":""},{"path":"/reference/compare_vectors.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compare embedding vectors — compare_vectors","text":"function returns matrix containing similarities pairs embedding vectors. matrix nrow(embedding) rows columns.","code":""},{"path":"/reference/compare_vectors.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Compare embedding vectors — compare_vectors","text":"Wulff, D. U., Aeschbach, S., & Mata, R. (2024). embeddeR. psyArXiv","code":""},{"path":"/reference/compare_vectors.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compare embedding vectors — compare_vectors","text":"","code":"# get embedding embedding <- embed(neo$text) #> Error in embed(neo$text): No API tokens exist. Set at least one token with set_tokens(). See ?set_tokens  # compare embedding vectors compare_vectors(embedding) #> Error in eval(expr, envir, enclos): object 'embedding' not found"},{"path":"/reference/embed.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate text embeddings — embed","title":"Generate text embeddings — embed","text":"embed generates embeddings input texts.","code":""},{"path":"/reference/embed.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate text embeddings — embed","text":"","code":"embed(text, api = \"huggingface\", model = NULL, type = NULL, verbose = FALSE)"},{"path":"/reference/embed.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate text embeddings — embed","text":"text character vector texts. api character string specifying api One c(\"huggingface\",\"openai\",\"cohere\"). Default \"huggingface\". model character string specifying model label. Must match model names corresponding APIs. See, huggingface.co/models, platform.openai.com/docs/models/embeddings, cohere.com/embeddings. Defaults \"sentence-transformers/-mpnet-base-v2\" api = \"huggingface\", \"text-embedding-ada-002\" api = \"openai\", \"embed-english-v3.0\" api = \"cohere\". type character string specifying type Cohere embeddings. One c(\"search_document\",\"search_query\",\"classification\",\"clustering\"). Default \"clustering\". See https://docs.cohere.com/reference/embed. verbose logical specifying whether show messages.","code":""},{"path":"/reference/embed.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate text embeddings — embed","text":"function returns matrix containing text embeddings length(text) rows many columns embedding dimensions.","code":""},{"path":"/reference/embed.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Generate text embeddings — embed","text":"Wulff, D. U., Aeschbach, S., & Mata, R. (2024). embeddeR. psyArXiv","code":""},{"path":"/reference/embed.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate text embeddings — embed","text":"","code":"# run embedding embed(neo$text) #> Error in embed(neo$text): No API tokens exist. Set at least one token with set_tokens(). See ?set_tokens"},{"path":"/reference/er_cluster.html","id":null,"dir":"Reference","previous_headings":"","what":"Cluster embedding vectors — er_cluster","title":"Cluster embedding vectors — er_cluster","text":"Function er_cluster generates clusters embedding vectors using standard clustering algorithms.","code":""},{"path":"/reference/er_cluster.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cluster embedding vectors — er_cluster","text":"","code":"er_cluster(   embedding,   method = \"hclust\",   k = NULL,   eps = NULL,   metric = \"arccos\",   ...,   verbose = FALSE )"},{"path":"/reference/er_cluster.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cluster embedding vectors — er_cluster","text":"embedding numeric matrix containing text embedding. method character string specifying clustering method One c(\"hclust\",\"dbscan\",\"louvain\"). Default \"hclust\". k integer specifying number clusters method = \"hclust\". eps numeric specifying within-cluster point distance method = \"dbscan\". metric character string specifying similarity function used methods c(\"hclust\",\"louvain\"). ... arguments passed clustering methods. Can used, e.g., specify linkage criterion hierarchical clustering (see hclust), minimum number points DBSCAN clustering (see dbscan), resolution Louvain clustering (see cluster_louvain). verbose logical specifying whether show messages.'","code":""},{"path":"/reference/er_cluster.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cluster embedding vectors — er_cluster","text":"function returns matrix containing input embedding, gained new attribute \"cluster\".","code":""},{"path":"/reference/er_cluster.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Cluster embedding vectors — er_cluster","text":"Wulff, D. U., Aeschbach, S., Hussain, Z., & Mata, R. (2024). embeddeR. preparation.","code":""},{"path":"/reference/er_cluster.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cluster embedding vectors — er_cluster","text":"","code":"# add clustering to embedding embedding <- er_cluster(embedding) #> Error in eval(expr, envir, enclos): object 'embedding' not found"},{"path":"/reference/er_compare_embeddings.html","id":null,"dir":"Reference","previous_headings":"","what":"Compare embeddings — er_compare_embeddings","title":"Compare embeddings — er_compare_embeddings","text":"Function er_compare_embeddings computes similarity two embeddings.","code":""},{"path":"/reference/er_compare_embeddings.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compare embeddings — er_compare_embeddings","text":"","code":"er_compare_embeddings(   embeddings,   metric = \"cosine\",   comparison_metric = \"spearman\" )"},{"path":"/reference/er_compare_embeddings.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compare embeddings — er_compare_embeddings","text":"embeddings list embedding matrices. metric character string specifying type similarity used produce similarity matrices embedding. One c(\"cosine\",\"arccos\",\"pearson\",\"spearman\"). Default \"cosine\". comparison_metric character string specifying type similarity used compare similarity matrices. One c(\"cosine\",\"arccos\",\"pearson\",\"spearman\"). Default \"spearman\".","code":""},{"path":"/reference/er_compare_embeddings.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compare embeddings — er_compare_embeddings","text":"function returns tibble containing every pair embeddings representational similarities overall (based lower triangle) per row (text).","code":""},{"path":"/reference/er_compare_embeddings.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Compare embeddings — er_compare_embeddings","text":"Wulff, D. U., Aeschbach, S., Hussain, Z., & Mata, R. (2024). embeddeR. preparation.","code":""},{"path":"/reference/er_compare_embeddings.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compare embeddings — er_compare_embeddings","text":"","code":"# get embedding embedding_1 <- embed(neo$text) embedding_2 <- embed(neo$text, model = \"distilbert-base-uncased\") #> Error in embed(neo$text, model = \"distilbert-base-uncased\"): unused argument (model = \"distilbert-base-uncased\")  # compute similarity compare_embeddings(list(embedding_1, embedding_2)) #> Error in compare_embeddings(list(embedding_1, embedding_2)): could not find function \"compare_embeddings\""},{"path":"/reference/er_compare_vectors.html","id":null,"dir":"Reference","previous_headings":"","what":"Compare embedding vectors — er_compare_vectors","title":"Compare embedding vectors — er_compare_vectors","text":"Function er_compare_vectors computes similarities embedding vectors.","code":""},{"path":"/reference/er_compare_vectors.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compare embedding vectors — er_compare_vectors","text":"","code":"er_compare_vectors(embedding, metric = \"cosine\")"},{"path":"/reference/er_compare_vectors.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compare embedding vectors — er_compare_vectors","text":"embedding numeric matrix containing text embedding. metric character string specifying type similarity. One c(\"cosine\",\"arccos\",\"pearson\",\"spearman\"). Default \"cosine\".","code":""},{"path":"/reference/er_compare_vectors.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compare embedding vectors — er_compare_vectors","text":"function returns matrix containing similarities pairs embedding vectors. matrix nrow(embedding) rows columns.","code":""},{"path":"/reference/er_compare_vectors.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Compare embedding vectors — er_compare_vectors","text":"Wulff, D. U., Aeschbach, Hussain, Z., S., & Mata, R. (2024). embeddeR. preparation.","code":""},{"path":"/reference/er_compare_vectors.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compare embedding vectors — er_compare_vectors","text":"","code":"# compute similarity matrix embedding <- compare_vectors(embedding) #> Error in compare_vectors(embedding): could not find function \"compare_vectors\""},{"path":"/reference/er_embed.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate text embeddings — er_embed","title":"Generate text embeddings — er_embed","text":"Function er_embed generates embeddings text inputs.","code":""},{"path":"/reference/er_embed.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate text embeddings — er_embed","text":"","code":"er_embed(text, api = \"huggingface\", model = NULL, type = NULL, verbose = FALSE)"},{"path":"/reference/er_embed.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate text embeddings — er_embed","text":"text character vector texts. api character string specifying embedding API. One c(\"huggingface\",\"openai\",\"cohere\"). Default \"huggingface\". model character string specifying embedding model. Must match model names corresponding APIs. See, huggingface.co/models, platform.openai.com/docs/models/embeddings, cohere.com/embeddings. Defaults \"sentence-transformers/-mpnet-base-v2\" api = \"huggingface\", \"text-embedding-ada-002\" api = \"openai\", \"embed-english-v3.0\" api = \"cohere\". type character string specifying type Cohere embeddings. One c(\"search_document\",\"search_query\",\"classification\",\"clustering\"). Default \"clustering\". See https://docs.cohere.com/reference/embed. verbose logical specifying whether show messages.","code":""},{"path":"/reference/er_embed.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate text embeddings — er_embed","text":"function returns matrix containing text embeddings length(text) rows many columns embedding dimensions.","code":""},{"path":"/reference/er_embed.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Generate text embeddings — er_embed","text":"Wulff, D. U., Aeschbach, S., Hussain, Z., & Mata, R. (2024). embeddeR. preparation.","code":""},{"path":"/reference/er_embed.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate text embeddings — er_embed","text":"","code":"# run embedding er_embed(neo$text) #> Error in er_embed(neo$text): No API tokens exist. Set at least one token with er_set_tokens(). See ?er_set_tokens"},{"path":"/reference/er_frame.html","id":null,"dir":"Reference","previous_headings":"","what":"Build data frame — er_frame","title":"Build data frame — er_frame","text":"Function er_frame transforms embedding embedding attributes tibble class embedR_tbl.","code":""},{"path":"/reference/er_frame.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Build data frame — er_frame","text":"","code":"er_frame(embedding)"},{"path":"/reference/er_frame.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Build data frame — er_frame","text":"embedding numeric matrix containing text embedding.","code":""},{"path":"/reference/er_frame.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Build data frame — er_frame","text":"function returns tibble containing embedding attributes.","code":""},{"path":"/reference/er_frame.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Build data frame — er_frame","text":"Wulff, D. U., Aeschbach, S., Hussain, Z., & Mata, R. (2024). embeddeR. psyArXiv","code":""},{"path":"/reference/er_frame.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Build data frame — er_frame","text":"","code":"# embed, project, and frame tbl <- er_embed(neo$text) %>%   er_project() %>%   er_frame() #> Error in er_embed(neo$text): No API tokens exist. Set at least one token with er_set_tokens(). See ?er_set_tokens"},{"path":"/reference/er_get_tokens.html","id":null,"dir":"Reference","previous_headings":"","what":"Get API tokens — er_get_tokens","title":"Get API tokens — er_get_tokens","text":"Function er_get_tokens lists existing access tokens embedding inference APIs.","code":""},{"path":"/reference/er_get_tokens.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get API tokens — er_get_tokens","text":"","code":"er_get_tokens()"},{"path":"/reference/er_get_tokens.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get API tokens — er_get_tokens","text":"function returns tibble showing previously defined access tokens.","code":""},{"path":"/reference/er_get_tokens.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Get API tokens — er_get_tokens","text":"Wulff, D. U., Aeschbach, S., Hussain, Z., & Mata, R. (2024). embeddeR. preparation.","code":""},{"path":"/reference/er_get_tokens.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get API tokens — er_get_tokens","text":"","code":"# retrieve access tokens er_get_tokens() #> No embedding API tokens found!"},{"path":"/reference/er_group.html","id":null,"dir":"Reference","previous_headings":"","what":"Group embedding vectors — er_group","title":"Group embedding vectors — er_group","text":"Function er_group condenses embedding grouping identical highly similar objects (rows).","code":""},{"path":"/reference/er_group.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Group embedding vectors — er_group","text":"","code":"er_group(embedding, method = \"identity\", threshold = 0.95, verbose = FALSE)"},{"path":"/reference/er_group.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Group embedding vectors — er_group","text":"embedding numeric matrix containing text embedding. method character string specifying grouping method. One c(\"identity\",\"fuzzy\"). Default \"identity\". threshold numeric specifying threshold method = \"fuzzy\". threshold argument defines quantile arccos similarity distribution used threshold grouping embedding objects. verbose logical specifying whether show messages.","code":""},{"path":"/reference/er_group.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Group embedding vectors — er_group","text":"function returns matrix containing grouped embedding. matrix still ncol(embedding) dimensions, rows reduced due grouping. method = \"identity\", matrix gains attribute frequency containing frequency table element original embedding. method = \"fuzzy\", matrix gains new attributes group_size, analogue frequency, group_texts, contains texts assigned group, group_min_sim, shows minimum arccos similarity texts group. Furthermore, method = \"fuzzy\", text column replaced generic group labels.","code":""},{"path":"/reference/er_group.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Group embedding vectors — er_group","text":"Wulff, D. U., Aeschbach, S., Hussain, Z., & Mata, R. (2024). embeddeR. psyArXiv","code":""},{"path":"/reference/er_group.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Group embedding vectors — er_group","text":"","code":"# get and group embedding vectors embedding <- er_embed(neo$text) %>%   er_group() #> Error in er_embed(neo$text): No API tokens exist. Set at least one token with er_set_tokens(). See ?er_set_tokens"},{"path":"/reference/er_infer_labels.html","id":null,"dir":"Reference","previous_headings":"","what":"Infer category labels — er_infer_labels","title":"Infer category labels — er_infer_labels","text":"er_infer_labels infers category labels using generative large language models.","code":""},{"path":"/reference/er_infer_labels.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Infer category labels — er_infer_labels","text":"","code":"er_infer_labels(   labels,   api = \"huggingface\",   model = NULL,   role = \"assistant\",   instruct = NULL,   system = NULL,   verbose = FALSE )"},{"path":"/reference/er_infer_labels.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Infer category labels — er_infer_labels","text":"labels list character vectors. api character string specifying api One c(\"huggingface\",\"openai\",\"cohere\"). Default \"openai\". model character string specifying model label. Must match model names corresponding APIs. See, huggingface.co/models platform.openai.com/docs/models/embeddings. Defaults \"meta-llama/Llama-2-70b-chat-hf\" api = \"huggingface\" \"gpt-4\" api = \"openai\". role character string specifying systems role place role general system instruction model. Default \"assistant\". instruct character string specifying instruction model. Must contain placeholder \"{examples}\". Default \"Generate specific accurate one two word category label captures common meaning following examples: {examples}. Place '@' category label.\". system character string specifying general system instruction model. Default \"helpful {role} provides short, specific, accurate category labels.\". verbose logical specifying whether show messages.'","code":""},{"path":"/reference/er_infer_labels.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Infer category labels — er_infer_labels","text":"function returns character vector category labels.","code":""},{"path":"/reference/er_infer_labels.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Infer category labels — er_infer_labels","text":"models recommended label inferences, including default models, free use using can result significant costs. Costs depend size input texts number labels inferred. default Hugging Face model, meta-llama/Llama-2-70b-chat-hf, requires PRO subscription monthly price. OpenAI models, including default gpt-4 model, incur costs based number tokens input output. obtain best possible labels recommended adjust prompt arguments role, system, instruct.","code":""},{"path":"/reference/er_infer_labels.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Infer category labels — er_infer_labels","text":"Wulff, D. U., Aeschbach, S., Hussain, Z., & Mata, R. (2024). embeddeR. psyArXiv","code":""},{"path":"/reference/er_infer_labels.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Infer category labels — er_infer_labels","text":"","code":"# get labeled results result <- er_embed(neo$text) %>%   er_group() %>%   er_project() %>%   er_frame() %>%   dplyr::mutate(group_labels = er_infer_labels(group_texts)) #> Error in er_embed(neo$text): No API tokens exist. Set at least one token with er_set_tokens(). See ?er_set_tokens"},{"path":"/reference/er_project.html","id":null,"dir":"Reference","previous_headings":"","what":"Project embedding — er_project","title":"Project embedding — er_project","text":"Function er_project projects embedding two dimensional space using non-linear dimensionality reduction techniques MDS, UMAP, PaCMAP.","code":""},{"path":"/reference/er_project.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Project embedding — er_project","text":"","code":"er_project(embedding, method = \"mds\", k = 2, ..., verbose = FALSE)"},{"path":"/reference/er_project.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Project embedding — er_project","text":"embedding numeric matrix containing text embedding. method character string specifying type projection. One c(\"mds\",\"umap\",\"pacmap\"). Default \"mds\". Projection method \"PaCMAP\" based Python library pacmap (see pypi.org/project/pacmap/) requires access python environment k integer determining number dimensions. Default 2. ... additional parameters handed projection method. verbose logical indicating whether show messages.","code":""},{"path":"/reference/er_project.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Project embedding — er_project","text":"function returns matrix containing embedding columns representing projected coordinates. matrix nrow(embedding) rows k columns.","code":""},{"path":"/reference/er_project.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Project embedding — er_project","text":"Wulff, D. U., Aeschbach, S., Hussain, Z., & Mata, R. (2024). embeddeR. preparation.","code":""},{"path":"/reference/er_project.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Project embedding — er_project","text":"","code":"# project embedding embedding <- embedding %>%   er_project() #> Error in eval(expr, envir, enclos): object 'embedding' not found"},{"path":"/reference/er_set_tokens.html","id":null,"dir":"Reference","previous_headings":"","what":"Set API tokens — er_set_tokens","title":"Set API tokens — er_set_tokens","text":"Function er_set_tokens sets access tokens embedding inference APIs.","code":""},{"path":"/reference/er_set_tokens.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set API tokens — er_set_tokens","text":"","code":"er_set_tokens(..., hard = FALSE)"},{"path":"/reference/er_set_tokens.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set API tokens — er_set_tokens","text":"... one api-token (name-value) pairs (e.g., huggingface = \"TOKEN\"). Names can one c(\"huggingface\",\"openai\",\"cohere\"). hard logical specifying whether existing tokens overwritten.","code":""},{"path":"/reference/er_set_tokens.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Set API tokens — er_set_tokens","text":"obtain API tokens users must register respective services: \"Hugging Face\"Sign huggingface.co/inference-api. go profile click settings. Generate access token Access Tokens sub-menu. \"OpenAI\"Sign openai.com/blog/openai-api. Select API. Click Personal (top-right) select View API keys. Create new secret key. \"Cohere\"Sign cohere.com. Select API keys personal dashboard. Either Create Trial key (free charge, rate limited) Create Production key (costly, unlimited). Hugging Face Cohere offer free--charge rate-limited API use.","code":""},{"path":"/reference/er_set_tokens.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Set API tokens — er_set_tokens","text":"Wulff, D. U., Aeschbach, S., Hussain, Z., & Mata, R. (2024). embeddeR. preparation.","code":""},{"path":"/reference/er_set_tokens.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Set API tokens — er_set_tokens","text":"","code":"# set hugging face token set_tokens(\"huggingface\" = \"TOKEN\") #> Error in set_tokens(huggingface = \"TOKEN\"): could not find function \"set_tokens\""},{"path":"/reference/frame.html","id":null,"dir":"Reference","previous_headings":"","what":"Create data frame — frame","title":"Create data frame — frame","text":"frame transforms embedding projections data frame, specifically, tibble.","code":""},{"path":"/reference/frame.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create data frame — frame","text":"","code":"frame(projection)"},{"path":"/reference/frame.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create data frame — frame","text":"projection numeric matrix containing text embedding projection generated k = 2.","code":""},{"path":"/reference/frame.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create data frame — frame","text":"function returns tibble containing projected embedding. projection dimensions assigned columns x y.","code":""},{"path":"/reference/frame.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Create data frame — frame","text":"Wulff, D. U., Aeschbach, S., & Mata, R. (2024). embeddeR. psyArXiv","code":""},{"path":"/reference/frame.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create data frame — frame","text":"","code":"# embed, project, to tibble projection <- embed(neo$text) %>%   project() %>%   to_tibble() #> Error in to_tibble(.): could not find function \"to_tibble\""},{"path":"/reference/get_tokens.html","id":null,"dir":"Reference","previous_headings":"","what":"Get API tokens — get_tokens","title":"Get API tokens — get_tokens","text":"get_tokens lists existing access tokens embedding APIs.","code":""},{"path":"/reference/get_tokens.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get API tokens — get_tokens","text":"","code":"get_tokens()"},{"path":"/reference/get_tokens.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get API tokens — get_tokens","text":"function returns tibble showing existing access tokens.","code":""},{"path":"/reference/get_tokens.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Get API tokens — get_tokens","text":"Wulff, D. U., Aeschbach, S., & Mata, R. (2024). embeddeR. psyArXiv","code":""},{"path":"/reference/get_tokens.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get API tokens — get_tokens","text":"","code":"# get embedding embedding <- embed(neo$text) #> Error in embed(neo$text): No API tokens exist. Set at least one token with set_tokens(). See ?set_tokens  # compute similarity compare_vectors(embedding) #> Error in eval(expr, envir, enclos): object 'embedding' not found"},{"path":"/reference/group.html","id":null,"dir":"Reference","previous_headings":"","what":"Group embedding or projection — group","title":"Group embedding or projection — group","text":"group transforms embedding projections tibble ready ggplot2.","code":""},{"path":"/reference/group.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Group embedding or projection — group","text":"","code":"group(embedding, method = \"identity\", threshold = 0.995, verbose = FALSE)"},{"path":"/reference/group.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Group embedding or projection — group","text":"embedding numeric matrix containing text embedding embedding projection. method character string specifying reduction method One c(\"identity\",\"fuzzy\"). Default \"identity\". threshold numeric specifying threshold method = fuzzy. verbose logical specifying whether show messages.'","code":""},{"path":"/reference/group.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Group embedding or projection — group","text":"function returns matrix containing embedding projection. matrix ncol(embedding) dimensions many rows determined condensing method. matrix gain attribute counts containing frequency table element original embedding projection.","code":""},{"path":"/reference/group.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Group embedding or projection — group","text":"Wulff, D. U., Aeschbach, S., & Mata, R. (2024). embeddeR. psyArXiv","code":""},{"path":"/reference/group.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Group embedding or projection — group","text":"","code":"# get embedding projection <- embed(neo$text) %>%   project() %>%   to_tibble() #> Error in to_tibble(.): could not find function \"to_tibble\""},{"path":"/reference/hello.html","id":null,"dir":"Reference","previous_headings":"","what":"Hello, World! — hello","title":"Hello, World! — hello","text":"Prints 'Hello, world!'.","code":""},{"path":"/reference/hello.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Hello, World! — hello","text":"","code":"hello()"},{"path":"/reference/hello.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Hello, World! — hello","text":"","code":"hello() #> Error in hello(): could not find function \"hello\""},{"path":"/reference/infer_labels.html","id":null,"dir":"Reference","previous_headings":"","what":"Reduce embedding or projection — infer_labels","title":"Reduce embedding or projection — infer_labels","text":"to_tibble transforms embedding projections tibble ready ggplot2.","code":""},{"path":"/reference/infer_labels.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reduce embedding or projection — infer_labels","text":"","code":"infer_labels(   labels,   api = \"huggingface\",   model = NULL,   role = \"assistant\",   instruct = NULL,   system = NULL,   verbose = FALSE )"},{"path":"/reference/infer_labels.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reduce embedding or projection — infer_labels","text":"labels list character vectors. api character string specifying api One c(\"huggingface\",\"openai\",\"cohere\"). Default \"openai\". model character string specifying model label. Must match model names corresponding APIs. See, huggingface.co/models, platform.openai.com/docs/models/embeddings, cohere.com/embeddings. Defaults \"meta-llama/Llama-2-70b-chat-hf\" api = \"huggingface\" \"gpt-4\" api = \"openai\". role character string specifying systems role place role general system instruction model. Default \"assistant\". instruct character string specifying instruction model. Must contain placeholder \"{examples}\". Default Generate specific accurate category label following examples: {examples}. Strictly respond single word.. system character string specifying general system instruction model. Default \"helpful honest \\code{role}, provides specific accurate category labels based examples.\". verbose logical specifying whether show messages.'","code":""},{"path":"/reference/infer_labels.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reduce embedding or projection — infer_labels","text":"function returns character vector category labels.","code":""},{"path":"/reference/infer_labels.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Reduce embedding or projection — infer_labels","text":"Note default Hugging Face model (meta-llama/Llama-2-70b-chat-hf) requires PRO subscription token extensive gpt-4 model can expensive.","code":""},{"path":"/reference/infer_labels.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Reduce embedding or projection — infer_labels","text":"Wulff, D. U., Aeschbach, S., & Mata, R. (2024). embeddeR. psyArXiv","code":""},{"path":"/reference/infer_labels.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reduce embedding or projection — infer_labels","text":"","code":"# get embedding projection <- embed(neo$text) %>%   project() %>%   to_tibble() #> Error in to_tibble(.): could not find function \"to_tibble\""},{"path":"/reference/neo.html","id":null,"dir":"Reference","previous_headings":"","what":"NEO personality items — neo","title":"NEO personality items — neo","text":"Personality items 300-item NEO personality questionnaire obtained IPIP.","code":""},{"path":"/reference/neo.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"NEO personality items — neo","text":"","code":"neo"},{"path":"/reference/neo.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"NEO personality items — neo","text":"tibble 300 personality items following columns: instrument Abbreviated name personality questionnaire. label Scale label. Scales aggregate ten items key Direction item. Used scale construction. text Text personality item.","code":""},{"path":"/reference/neo.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"NEO personality items — neo","text":"https://ipip.ori.org/","code":""},{"path":"/reference/neo.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"NEO personality items — neo","text":"Wulff, D. U., & Mata, R. (2023, October 12). Automated jingle–jangle detection: Using embeddings tackle taxonomic incommensurability. https://doi.org/10.31234/osf.io/9h7aw","code":""},{"path":"/reference/pacmap.html","id":null,"dir":"Reference","previous_headings":"","what":"Run PaCMAP — pacmap","title":"Run PaCMAP — pacmap","text":"Run PaCMAP dimensionality reduction","code":""},{"path":"/reference/pacmap.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run PaCMAP — pacmap","text":"","code":"pacmap(   embedding,   n_components = 2,   n_neighbors = 10,   MN_ratio = 0.5,   FP_ratio = 2,   distance = \"euclidean\",   lr = 1,   num_iters = 450,   verbose = FALSE,   apply_pca = TRUE )"},{"path":"/reference/pacmap.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run PaCMAP — pacmap","text":"embedding numeric matrix containing text embedding. n_components integer Dimensions embedded space. Default 2. n_neighbors integer specifying number neighbors considered nearest neighbor pairs local structure preservation. Default 10. MN_ratio numeric specifying ratio mid-near pairs nearest-neighbor pairs  (e.g. n_neighbors=10, MN_ratio=0.5 means 5 mid-near pairs). Mid-near pairs used global structure preservation. Default .5. FP_ratio numeric specifying ratio pairs nearest-neighbor pairs (e.g. n_neighbors=10, FP_ratio=2 means 20 pairs). pairs used local global structure preservation. Default 2. distance character string specifying distance metric. One c(\"euclidean\", \"manhattan\", \"angular\", \"hamming\"). Default \"euclidean\". lr numeric specifying learning rate Adam optimizer embedding. Default 1. num_iters integer specifying number iterations optimization embedding. Values greater 250 recommended. Default 450. verbose logical specifying whether show messages initialization fitting. Default FALSE. apply_pca: logical specifying whether apply PCA data pair construction. Default FALSE.","code":""},{"path":"/reference/pacmap.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Run PaCMAP — pacmap","text":"function returns matrix containing projected coordinates embedding vectors. matrix nrow(embedding) rows n_components columns.","code":""},{"path":"/reference/pacmap.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Run PaCMAP — pacmap","text":"Function wraps around PaCMAP Python module found github.com/YingfanWang/PaCMAP. Function adapted /github.com/milescsmith/ReductionWrappers. PaCMAP (Pairwise Controlled Manifold Approximation) Maps high-dimensionaldataset low-dimensional embedding. details see jmlr.org/papers/volume22/20-1061/20-1061.pdf.","code":""},{"path":"/reference/pipe.html","id":null,"dir":"Reference","previous_headings":"","what":"Pipe operator — %>%","title":"Pipe operator — %>%","text":"See magrittr::%>% details.","code":""},{"path":"/reference/pipe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pipe operator — %>%","text":"","code":"lhs %>% rhs"},{"path":"/reference/pipe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pipe operator — %>%","text":"lhs value magrittr placeholder. rhs function call using magrittr semantics.","code":""},{"path":"/reference/pipe.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pipe operator — %>%","text":"result calling `rhs(lhs)`.","code":""},{"path":"/reference/plot.embedR.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot embedding — plot.embedR","title":"Plot embedding — plot.embedR","text":"Generic function plot shows points two-dimensional embedding projection space options customization.","code":""},{"path":"/reference/plot.embedR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot embedding — plot.embedR","text":"","code":"# S3 method for embedR plot(embedding, ...)"},{"path":"/reference/plot.embedR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot embedding — plot.embedR","text":"embedding numeric matrix containing text embedding.","code":""},{"path":"/reference/plot.embedR.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot embedding — plot.embedR","text":"function returns ggplot2 object.","code":""},{"path":"/reference/plot.embedR.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot embedding — plot.embedR","text":"function wraps around er_frame plot.embedR_tbl.","code":""},{"path":"/reference/plot.embedR.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Plot embedding — plot.embedR","text":"Wulff, D. U., Aeschbach, S., Hussain, Z., & Mata, R. (2024). embeddeR. preparation.","code":""},{"path":"/reference/plot.embedR.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot embedding — plot.embedR","text":"","code":"# get embedding plot neo$text %>%   er_embed() %>%   er_project() %>%   plot() #> Error in er_embed(.): No API tokens exist. Set at least one token with er_set_tokens(). See ?er_set_tokens"},{"path":"/reference/plot.embedR_tbl.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot embedding frame — plot.embedR_tbl","title":"Plot embedding frame — plot.embedR_tbl","text":"Generic function plot shows points two-dimensional embedding projection space options customization.","code":""},{"path":"/reference/plot.embedR_tbl.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot embedding frame — plot.embedR_tbl","text":"","code":"# S3 method for embedR_tbl plot(   data,   dimensions = c(1, 2),   size = NULL,   color = NULL,   label = NULL,   label_size = 3,   label_filter = NULL,   pt_padding = 0.05,   box_padding = 0.05,   viridis_set = \"E\",   viridis_limits = c(0, 0.9) )"},{"path":"/reference/plot.embedR_tbl.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot embedding frame — plot.embedR_tbl","text":"data data.frame created using er_frame. dimensions integer vector determining dimensions plotted. Default c(1, 2). size optional character string specifying column used determine point size. color optional character string specifying column used determine point (label) color. label optional character string specifying column used determine label texts. label_size optional character string specifying column used determine label size. label_filter optional logical comparison determining label texts show plot. Can based columns data. pt_padding numeric specifying point padding. box_padding numeric specifying label box padding. viridis_set character string determining viridis color set. See scale_color_viridis_d. viridis_limits numeric vector length 2 determining begin end arguments scale_color_viridis_d.","code":""},{"path":"/reference/plot.embedR_tbl.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot embedding frame — plot.embedR_tbl","text":"function returns ggplot2 object.","code":""},{"path":"/reference/plot.embedR_tbl.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Plot embedding frame — plot.embedR_tbl","text":"Wulff, D. U., Aeschbach, S., Hussain, Z., & Mata, R. (2024). embeddeR. preparation.","code":""},{"path":"/reference/plot.embedR_tbl.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot embedding frame — plot.embedR_tbl","text":"","code":"# get embedding plot neo$text %>%   er_embed() %>%   er_project() %>%   er_frame() #> Error in er_embed(.): No API tokens exist. Set at least one token with er_set_tokens(). See ?er_set_tokens   plot() #> Error in plot.default(): argument \"x\" is missing, with no default"},{"path":"/reference/plot.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot projection — plot","title":"Plot projection — plot","text":"project projects embedding two dimensional space.","code":""},{"path":"/reference/plot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot projection — plot","text":"","code":"plot(embedding, method = \"mds\", k = 2, ..., verbose = FALSE)"},{"path":"/reference/plot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot projection — plot","text":"embedding numeric matrix containing text embedding. method character string specifying type projection. One c(\"mds\",\"umap\",\"pacmap\"). Default \"mds\". k integer determining number dimensions. Default 2. ... additional parameters handed embedding method. verbose logical indicating whether show messages.","code":""},{"path":"/reference/plot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot projection — plot","text":"function returns matrix containing projected coordinates embedding vectors. matrix nrow(embedding) rows k columns.","code":""},{"path":"/reference/plot.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Plot projection — plot","text":"Wulff, D. U., Aeschbach, S., & Mata, R. (2024). embeddeR. psyArXiv","code":""},{"path":"/reference/plot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot projection — plot","text":"","code":"# get embedding embedding <- embed(neo$text) #> Error in embed(neo$text): No API tokens exist. Set at least one token with set_tokens(). See ?set_tokens  # project embedding project(embedding) #> Error in eval(expr, envir, enclos): object 'embedding' not found"},{"path":"/reference/print.embedR.html","id":null,"dir":"Reference","previous_headings":"","what":"Print embedding object — print.embedR","title":"Print embedding object — print.embedR","text":"Generic function print.embedR shows print embedding object abbreviated matrix tibble attributes.","code":""},{"path":"/reference/print.embedR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print embedding object — print.embedR","text":"","code":"# S3 method for embedR print(x, n = 5, m = 5, ...)"},{"path":"/reference/print.embedR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print embedding object — print.embedR","text":"x object class embedR n integer specifying number rows print. Default 5. m integer specifying number columns print. Default 5. ... arguments passed methods.","code":""},{"path":"/reference/project.html","id":null,"dir":"Reference","previous_headings":"","what":"Project embedding — project","title":"Project embedding — project","text":"project projects embedding two dimensional space.","code":""},{"path":"/reference/project.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Project embedding — project","text":"","code":"project(embedding, method = \"mds\", k = 2, ..., verbose = FALSE)"},{"path":"/reference/project.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Project embedding — project","text":"embedding numeric matrix containing text embedding. method character string specifying type projection. One c(\"mds\",\"umap\",\"pacmap\"). Default \"mds\". k integer determining number dimensions. Default 2. ... additional parameters handed embedding method. verbose logical indicating whether show messages.","code":""},{"path":"/reference/project.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Project embedding — project","text":"function returns matrix containing projected coordinates embedding vectors. matrix nrow(embedding) rows k columns.","code":""},{"path":"/reference/project.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Project embedding — project","text":"Wulff, D. U., Aeschbach, S., & Mata, R. (2024). embeddeR. psyArXiv","code":""},{"path":"/reference/project.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Project embedding — project","text":"","code":"# get embedding embedding <- embed(neo$text) #> Error in embed(neo$text): No API tokens exist. Set at least one token with set_tokens(). See ?set_tokens  # project embedding project(embedding) #> Error in eval(expr, envir, enclos): object 'embedding' not found"},{"path":"/reference/set_tokens.html","id":null,"dir":"Reference","previous_headings":"","what":"Set API tokens — set_tokens","title":"Set API tokens — set_tokens","text":"set_tokens sets access tokens embedding APIs.","code":""},{"path":"/reference/set_tokens.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set API tokens — set_tokens","text":"","code":"set_tokens(..., hard = FALSE)"},{"path":"/reference/set_tokens.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set API tokens — set_tokens","text":"... one api-token (name-value) pairs (e.g., huggingface = \"TOKEN\"). Names can one c(\"huggingface\",\"openai\",\"cohere\"). hard logical specifying whether tokens overwritten.","code":""},{"path":"/reference/set_tokens.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Set API tokens — set_tokens","text":"function returns matrix containing similarities pairs embedding vectors. matrix nrow(embedding) rows columns.","code":""},{"path":"/reference/set_tokens.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Set API tokens — set_tokens","text":"obtain API tokens users must register respective services: \"Hugging Face\"Sign huggingface.co/inference-api. go profile click settings. Generate access token Access Tokens sub-menu. \"OpenAI\"Sign openai.com/blog/openai-api. Select API. Click Personal (top-right) select View API keys. Create new secret key. \"Cohere\"Sign cohere.com. Select API keys personal dashboard. Either Create Trial key (free charge, rate limited) Create Production key (costly, unlimited). Hugging Face Cohere offer free--charge rate-limited API use.","code":""},{"path":"/reference/set_tokens.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Set API tokens — set_tokens","text":"Wulff, D. U., Aeschbach, S., & Mata, R. (2024). embeddeR. psyArXiv","code":""},{"path":"/reference/set_tokens.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Set API tokens — set_tokens","text":"","code":"# get hugging face token set_tokens(\"huggingface\" = \"TOKEN\")"},{"path":"/reference/text2sdg.html","id":null,"dir":"Reference","previous_headings":"","what":"Embed and analyze text — text2sdg","title":"Embed and analyze text — text2sdg","text":"embedR package open-source R package generate analyze text embeddings. gives access state---art open paid APIs Hugging Face, OpenAI, (Cohere) gnerate text embeddings offers methods group, project, relabel, visualize .","code":""},{"path":"/reference/text2sdg.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Embed and analyze text — text2sdg","text":"following provides overview package's functions:","code":""},{"path":"/reference/text2sdg.html","id":"tokens","dir":"Reference","previous_headings":"","what":"Tokens","title":"Embed and analyze text — text2sdg","text":"er_set_tokens sets access tokens APIs Hugging Face, OpenAI, Cohere. er_get_tokens shows tokens set current session.","code":""},{"path":"/reference/text2sdg.html","id":"embed","dir":"Reference","previous_headings":"","what":"Embed","title":"Embed and analyze text — text2sdg","text":"er_embed generates state---art text embeddings using APIs Hugging Face, OpenAI, (Cohere).","code":""},{"path":"/reference/text2sdg.html","id":"process","dir":"Reference","previous_headings":"","what":"Process","title":"Embed and analyze text — text2sdg","text":".  er_group groups identical highly similar embedding vectors produce group-based embeddings. er_project projects embeddings smaller dimensional spaces using MDS, UMAP, PaCMAP.","code":""},{"path":"/reference/text2sdg.html","id":"analyze","dir":"Reference","previous_headings":"","what":"Analyze","title":"Embed and analyze text — text2sdg","text":"er_compare_vectors computes similarity matrix containing similarities pairs embedding vectors. er_compare_embeddings computes representational similarity pairs embeddings. er_cluster clusters embedding vectors larger groups using hierarchical clustering, dbscan, louvain clustering.","code":""},{"path":"/reference/text2sdg.html","id":"helper","dir":"Reference","previous_headings":"","what":"Helper","title":"Embed and analyze text — text2sdg","text":"er_frame generates tibble embedding objects including potential attributes. er_infer_labels uses state---art generatiev models Hugging Face OpenAI generate category labels groups texts.","code":""},{"path":"/reference/text2sdg.html","id":"visualize","dir":"Reference","previous_headings":"","what":"Visualize","title":"Embed and analyze text — text2sdg","text":"plot produces 2D scatterplot embedding vectors (typically projection) options customization.","code":""},{"path":"/reference/text2sdg.html","id":"data","dir":"Reference","previous_headings":"","what":"Data","title":"Embed and analyze text — text2sdg","text":"neo ai","code":""},{"path":"/reference/text2sdg.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Embed and analyze text — text2sdg","text":"","code":"# \\donttest{ # load package library(embedR)  # set api tokens er_set_token(\"openai\" = \"TOKEN\",              \"huggingface\" = \"TOKEN\",              \"cohere\" = \"TOKEN\") #> Error in er_set_token(openai = \"TOKEN\", huggingface = \"TOKEN\", cohere = \"TOKEN\"): could not find function \"er_set_token\"  # generate embedding embedding = neo$text %>%    # generate text embedding   er_embed(api = \"openai\") #> Error in er_embed(., api = \"openai\"): No API tokens exist. Set at least one token with er_set_tokens(). See ?er_set_tokens  # analyze embedding result = embedding %>%    # group similar texts   er_group(method = \"fuzzy\") %>%    # generate 2D projection   er_project(method = \"umap\") %>%    # cluster projection   er_cluster(method = \"louvain\") %>%    # produce data frame   er_frame() #> Error in eval(expr, envir, enclos): object 'embedding' not found  # re-label text groups result = embedding %>%    # relabel groups   er_mutate(labels = label(group_texts,                            api = \"openai\")) #> Error in er_mutate(., labels = label(group_texts, api = \"openai\")): could not find function \"er_mutate\"  # visualize result %>% plot() #> Error in eval(expr, envir, enclos): object 'result' not found # }"}]
