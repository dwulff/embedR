[{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Dirk U. Wulff. Author, maintainer. Samuel Aeschbach. Contributor. Zak Hussain. Contributor. Rui Mata. Contributor.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Wulff DU (2023). embedR: Embed analyze text. R package version 0.1.0, https://CRAN.R-project.org/package=embedR.","code":"@Manual{,   title = {embedR: Embed and analyze text},   author = {Dirk U. Wulff},   year = {2023},   note = {R package version 0.1.0},   url = {https://CRAN.R-project.org/package=embedR}, }"},{"path":"/index.html","id":"embedr","dir":"","previous_headings":"","what":"Embed and analyze text","title":"Embed and analyze text","text":"embedR package open-source R package generate analyze text embeddings. uses open paid APIs Hugging Face, OpenAI, Cohere offers various options generate, group, project, relabel, visualize text embeddings.","code":""},{"path":"/index.html","id":"general-information","dir":"","previous_headings":"","what":"General Information","title":"Embed and analyze text","text":"text2sdg package developed Dirk U. Wulff, contributions Samuel Aeschbach, Zak Hussain, Rui Mata. published GNU General Public License. overview package can accessed online within R using ?embedR.","code":""},{"path":"/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Embed and analyze text","text":"latest development version GitHub can installed via devtools::install_github(\"dwulff/embedR\"). Note requires prior installation devtools package.","code":""},{"path":"/index.html","id":"caution","dir":"","previous_headings":"","what":"Caution","title":"Embed and analyze text","text":"Use package can result data security violations. package involves function send data servers external APIs providers, including Hugging Face, OpenAI, Cohere.","code":""},{"path":"/index.html","id":"usage","dir":"","previous_headings":"","what":"Usage","title":"Embed and analyze text","text":"","code":"# load package library(embedR)  # vector of texts texts = c(\"This is text 1\", \"This is text 2\")  # set api tokens set_token(\"openai\" = \"TOKEN\",           \"huggingface\" = \"TOKEN\",           \"cohere\" = \"TOKEN\")  # analyze result = texts %>%     # generate text embedding   embed(api = \"openai\") %>%       # group similar texts   group(method = \"fuzzy\") %>%       # generate 2D projection   project(method = \"umap\") %>%       # cluster projection   cluster(method = \"dbscan\") %>%       # produce data frame   frame() %>%       # relabel groups   mutate(labels = label(group_texts,                          api = \"openai\"))                          # visualize result %>% visualize()"},{"path":"/index.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Embed and analyze text","text":"added.","code":""},{"path":"/reference/compare_embeddings.html","id":null,"dir":"Reference","previous_headings":"","what":"Compare embeddings — compare_embeddings","title":"Compare embeddings — compare_embeddings","text":"compare_embeddings computes similarity two embeddings.","code":""},{"path":"/reference/compare_embeddings.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compare embeddings — compare_embeddings","text":"","code":"compare_embeddings(   embeddings,   metric = \"cosine\",   comparison_metric = \"spearman\" )"},{"path":"/reference/compare_embeddings.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compare embeddings — compare_embeddings","text":"embeddings list embedding matrices. metric character string specifying type similarity used produce similarity matrices embedding. One c(\"cosine\",\"arccos\",\"pearson\",\"spearman\"). Default \"cosine\". comparison_metric character string specifying type similarity used compare similarity matrices. One c(\"cosine\",\"arccos\",\"pearson\",\"spearman\"). Default \"spearman\".","code":""},{"path":"/reference/compare_embeddings.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compare embeddings — compare_embeddings","text":"function returns tibble containing representational similarities every pair embeddings overall (based lower triangle) per row.","code":""},{"path":"/reference/compare_embeddings.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Compare embeddings — compare_embeddings","text":"Wulff, D. U., Aeschbach, S., & Mata, R. (2024). embeddeR. psyArXiv","code":""},{"path":"/reference/compare_embeddings.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compare embeddings — compare_embeddings","text":"","code":"# get embedding embedding_1 <- embed(neo$text) #> Error in embed(neo$text): No API tokens exist. Set at least one token with set_tokens(). See ?set_tokens embedding_2 <- embed(neo$text, model = \"distilbert-base-uncased\") #> Error in embed(neo$text, model = \"distilbert-base-uncased\"): No API tokens exist. Set at least one token with set_tokens(). See ?set_tokens  # compute similarity compare_embeddings(list(embedding_1, embedding_2)) #> Error in eval(expr, envir, enclos): object 'embedding_1' not found"},{"path":"/reference/compare_vectors.html","id":null,"dir":"Reference","previous_headings":"","what":"Compare embedding vectors — compare_vectors","title":"Compare embedding vectors — compare_vectors","text":"compare computes similarities embedding vectors.","code":""},{"path":"/reference/compare_vectors.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compare embedding vectors — compare_vectors","text":"","code":"compare_vectors(embedding, metric = \"cosine\")"},{"path":"/reference/compare_vectors.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compare embedding vectors — compare_vectors","text":"embedding numeric matrix containing text embedding. metric character string specifying type similarity. One c(\"cosine\",\"arccos\",\"pearson\",\"spearman\"). Default \"cosine\".","code":""},{"path":"/reference/compare_vectors.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compare embedding vectors — compare_vectors","text":"function returns matrix containing similarities pairs embedding vectors. matrix nrow(embedding) rows columns.","code":""},{"path":"/reference/compare_vectors.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Compare embedding vectors — compare_vectors","text":"Wulff, D. U., Aeschbach, S., & Mata, R. (2024). embeddeR. psyArXiv","code":""},{"path":"/reference/compare_vectors.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compare embedding vectors — compare_vectors","text":"","code":"# get embedding embedding <- embed(neo$text) #> Error in embed(neo$text): No API tokens exist. Set at least one token with set_tokens(). See ?set_tokens  # compare embedding vectors compare_vectors(embedding) #> Error in eval(expr, envir, enclos): object 'embedding' not found"},{"path":"/reference/embed.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate text embeddings — embed","title":"Generate text embeddings — embed","text":"embed generates embeddings input texts.","code":""},{"path":"/reference/embed.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate text embeddings — embed","text":"","code":"embed(text, api = \"huggingface\", model = NULL, type = NULL, verbose = FALSE)"},{"path":"/reference/embed.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate text embeddings — embed","text":"text character vector texts. api character string specifying api One c(\"huggingface\",\"openai\",\"cohere\"). Default \"huggingface\". model character string specifying model label. Must match model names corresponding APIs. See, huggingface.co/models, platform.openai.com/docs/models/embeddings, cohere.com/embeddings. Defaults \"sentence-transformers/-mpnet-base-v2\" api = \"huggingface\", \"text-embedding-ada-002\" api = \"openai\", \"embed-english-v3.0\" api = \"cohere\". type character string specifying type Cohere embeddings. One c(\"search_document\",\"search_query\",\"classification\",\"clustering\"). Default \"clustering\". See https://docs.cohere.com/reference/embed. verbose logical specifying whether show messages.","code":""},{"path":"/reference/embed.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate text embeddings — embed","text":"function returns matrix containing text embeddings length(text) rows many columns embedding dimensions.","code":""},{"path":"/reference/embed.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Generate text embeddings — embed","text":"Wulff, D. U., Aeschbach, S., & Mata, R. (2024). embeddeR. psyArXiv","code":""},{"path":"/reference/embed.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate text embeddings — embed","text":"","code":"# run embedding embed(neo$text) #> Error in embed(neo$text): No API tokens exist. Set at least one token with set_tokens(). See ?set_tokens"},{"path":"/reference/frame.html","id":null,"dir":"Reference","previous_headings":"","what":"Create data frame — frame","title":"Create data frame — frame","text":"frame transforms embedding projections data frame, specifically, tibble.","code":""},{"path":"/reference/frame.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create data frame — frame","text":"","code":"frame(projection)"},{"path":"/reference/frame.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create data frame — frame","text":"projection numeric matrix containing text embedding projection generated k = 2.","code":""},{"path":"/reference/frame.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create data frame — frame","text":"function returns tibble containing projected embedding. projection dimensions assigned columns x y.","code":""},{"path":"/reference/frame.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Create data frame — frame","text":"Wulff, D. U., Aeschbach, S., & Mata, R. (2024). embeddeR. psyArXiv","code":""},{"path":"/reference/frame.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create data frame — frame","text":"","code":"# embed, project, to tibble projection <- embed(neo$text) %>%   project() %>%   to_tibble() #> Error in to_tibble(.): could not find function \"to_tibble\""},{"path":"/reference/get_tokens.html","id":null,"dir":"Reference","previous_headings":"","what":"Get API tokens — get_tokens","title":"Get API tokens — get_tokens","text":"get_tokens lists existing access tokens embedding APIs.","code":""},{"path":"/reference/get_tokens.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get API tokens — get_tokens","text":"","code":"get_tokens()"},{"path":"/reference/get_tokens.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get API tokens — get_tokens","text":"function returns tibble showing existing access tokens.","code":""},{"path":"/reference/get_tokens.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Get API tokens — get_tokens","text":"Wulff, D. U., Aeschbach, S., & Mata, R. (2024). embeddeR. psyArXiv","code":""},{"path":"/reference/get_tokens.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get API tokens — get_tokens","text":"","code":"# get embedding embedding <- embed(neo$text) #> Error in embed(neo$text): No API tokens exist. Set at least one token with set_tokens(). See ?set_tokens  # compute similarity compare_vectors(embedding) #> Error in eval(expr, envir, enclos): object 'embedding' not found"},{"path":"/reference/group.html","id":null,"dir":"Reference","previous_headings":"","what":"Group embedding or projection — group","title":"Group embedding or projection — group","text":"group transforms embedding projections tibble ready ggplot2.","code":""},{"path":"/reference/group.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Group embedding or projection — group","text":"","code":"group(embedding, method = \"identity\", threshold = 0.995, verbose = FALSE)"},{"path":"/reference/group.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Group embedding or projection — group","text":"embedding numeric matrix containing text embedding embedding projection. method character string specifying reduction method One c(\"identity\",\"fuzzy\"). Default \"identity\". threshold numeric specifying threshold method = fuzzy. verbose logical specifying whether show messages.'","code":""},{"path":"/reference/group.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Group embedding or projection — group","text":"function returns matrix containing embedding projection. matrix ncol(embedding) dimensions many rows determined condensing method. matrix gain attribute counts containing frequency table element original embedding projection.","code":""},{"path":"/reference/group.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Group embedding or projection — group","text":"Wulff, D. U., Aeschbach, S., & Mata, R. (2024). embeddeR. psyArXiv","code":""},{"path":"/reference/group.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Group embedding or projection — group","text":"","code":"# get embedding projection <- embed(neo$text) %>%   project() %>%   to_tibble() #> Error in to_tibble(.): could not find function \"to_tibble\""},{"path":"/reference/hello.html","id":null,"dir":"Reference","previous_headings":"","what":"Hello, World! — hello","title":"Hello, World! — hello","text":"Prints 'Hello, world!'.","code":""},{"path":"/reference/hello.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Hello, World! — hello","text":"","code":"hello()"},{"path":"/reference/hello.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Hello, World! — hello","text":"","code":"hello() #> Error in hello(): could not find function \"hello\""},{"path":"/reference/infer_labels.html","id":null,"dir":"Reference","previous_headings":"","what":"Reduce embedding or projection — infer_labels","title":"Reduce embedding or projection — infer_labels","text":"to_tibble transforms embedding projections tibble ready ggplot2.","code":""},{"path":"/reference/infer_labels.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reduce embedding or projection — infer_labels","text":"","code":"infer_labels(   labels,   api = \"huggingface\",   model = NULL,   role = \"assistant\",   instruct = NULL,   system = NULL,   verbose = FALSE )"},{"path":"/reference/infer_labels.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reduce embedding or projection — infer_labels","text":"labels list character vectors. api character string specifying api One c(\"huggingface\",\"openai\",\"cohere\"). Default \"openai\". model character string specifying model label. Must match model names corresponding APIs. See, huggingface.co/models, platform.openai.com/docs/models/embeddings, cohere.com/embeddings. Defaults \"meta-llama/Llama-2-70b-chat-hf\" api = \"huggingface\" \"gpt-4\" api = \"openai\". role character string specifying systems role place role general system instruction model. Default \"assistant\". instruct character string specifying instruction model. Must contain placeholder \"{examples}\". Default Generate specific accurate category label following examples: {examples}. Strictly respond single word.. system character string specifying general system instruction model. Default \"helpful honest \\code{role}, provides specific accurate category labels based examples.\". verbose logical specifying whether show messages.'","code":""},{"path":"/reference/infer_labels.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reduce embedding or projection — infer_labels","text":"function returns character vector category labels.","code":""},{"path":"/reference/infer_labels.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Reduce embedding or projection — infer_labels","text":"Note default Hugging Face model (meta-llama/Llama-2-70b-chat-hf) requires PRO subscription token extensive gpt-4 model can expensive.","code":""},{"path":"/reference/infer_labels.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Reduce embedding or projection — infer_labels","text":"Wulff, D. U., Aeschbach, S., & Mata, R. (2024). embeddeR. psyArXiv","code":""},{"path":"/reference/infer_labels.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reduce embedding or projection — infer_labels","text":"","code":"# get embedding projection <- embed(neo$text) %>%   project() %>%   to_tibble() #> Error in to_tibble(.): could not find function \"to_tibble\""},{"path":"/reference/pacmap.html","id":null,"dir":"Reference","previous_headings":"","what":"Run PaCMAP — pacmap","title":"Run PaCMAP — pacmap","text":"Run PaCMAP dimensionality reduction","code":""},{"path":"/reference/pacmap.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run PaCMAP — pacmap","text":"","code":"pacmap(   embedding,   n_components = 2,   n_neighbors = 10,   MN_ratio = 0.5,   FP_ratio = 2,   distance = \"euclidean\",   lr = 1,   num_iters = 450,   verbose = FALSE,   apply_pca = TRUE )"},{"path":"/reference/pacmap.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run PaCMAP — pacmap","text":"embedding numeric matrix containing text embedding. n_components integer Dimensions embedded space. Default 2. n_neighbors integer specifying number neighbors considered nearest neighbor pairs local structure preservation. Default 10. MN_ratio numeric specifying ratio mid-near pairs nearest-neighbor pairs  (e.g. n_neighbors=10, MN_ratio=0.5 means 5 mid-near pairs). Mid-near pairs used global structure preservation. Default .5. FP_ratio numeric specifying ratio pairs nearest-neighbor pairs (e.g. n_neighbors=10, FP_ratio=2 means 20 pairs). pairs used local global structure preservation. Default 2. distance character string specifying distance metric. One c(\"euclidean\", \"manhattan\", \"angular\", \"hamming\"). Default \"euclidean\". lr numeric specifying learning rate Adam optimizer embedding. Default 1. num_iters integer specifying number iterations optimization embedding. Values greater 250 recommended. Default 450. verbose logical specifying whether show messages initialization fitting. Default FALSE. apply_pca: logical specifying whether apply PCA data pair construction. Default FALSE.","code":""},{"path":"/reference/pacmap.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Run PaCMAP — pacmap","text":"function returns matrix containing projected coordinates embedding vectors. matrix nrow(embedding) rows n_components columns.","code":""},{"path":"/reference/pacmap.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Run PaCMAP — pacmap","text":"Function wraps around PaCMAP Python module found github.com/YingfanWang/PaCMAP. Function adapted /github.com/milescsmith/ReductionWrappers. PaCMAP (Pairwise Controlled Manifold Approximation) Maps high-dimensionaldataset low-dimensional embedding. details see jmlr.org/papers/volume22/20-1061/20-1061.pdf.","code":""},{"path":"/reference/pipe.html","id":null,"dir":"Reference","previous_headings":"","what":"Pipe operator — %>%","title":"Pipe operator — %>%","text":"See magrittr::%>% details.","code":""},{"path":"/reference/pipe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pipe operator — %>%","text":"","code":"lhs %>% rhs"},{"path":"/reference/pipe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pipe operator — %>%","text":"lhs value magrittr placeholder. rhs function call using magrittr semantics.","code":""},{"path":"/reference/pipe.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pipe operator — %>%","text":"result calling `rhs(lhs)`.","code":""},{"path":"/reference/plot.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot projection — plot","title":"Plot projection — plot","text":"project projects embedding two dimensional space.","code":""},{"path":"/reference/plot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot projection — plot","text":"","code":"plot(embedding, method = \"mds\", k = 2, ..., verbose = FALSE)"},{"path":"/reference/plot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot projection — plot","text":"embedding numeric matrix containing text embedding. method character string specifying type projection. One c(\"mds\",\"umap\",\"pacmap\"). Default \"mds\". k integer determining number dimensions. Default 2. ... additional parameters handed embedding method. verbose logical indicating whether show messages.","code":""},{"path":"/reference/plot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot projection — plot","text":"function returns matrix containing projected coordinates embedding vectors. matrix nrow(embedding) rows k columns.","code":""},{"path":"/reference/plot.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Plot projection — plot","text":"Wulff, D. U., Aeschbach, S., & Mata, R. (2024). embeddeR. psyArXiv","code":""},{"path":"/reference/plot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot projection — plot","text":"","code":"# get embedding embedding <- embed(neo$text) #> Error in embed(neo$text): No API tokens exist. Set at least one token with set_tokens(). See ?set_tokens  # project embedding project(embedding) #> Error in eval(expr, envir, enclos): object 'embedding' not found"},{"path":"/reference/project.html","id":null,"dir":"Reference","previous_headings":"","what":"Project embedding — project","title":"Project embedding — project","text":"project projects embedding two dimensional space.","code":""},{"path":"/reference/project.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Project embedding — project","text":"","code":"project(embedding, method = \"mds\", k = 2, ..., verbose = FALSE)"},{"path":"/reference/project.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Project embedding — project","text":"embedding numeric matrix containing text embedding. method character string specifying type projection. One c(\"mds\",\"umap\",\"pacmap\"). Default \"mds\". k integer determining number dimensions. Default 2. ... additional parameters handed embedding method. verbose logical indicating whether show messages.","code":""},{"path":"/reference/project.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Project embedding — project","text":"function returns matrix containing projected coordinates embedding vectors. matrix nrow(embedding) rows k columns.","code":""},{"path":"/reference/project.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Project embedding — project","text":"Wulff, D. U., Aeschbach, S., & Mata, R. (2024). embeddeR. psyArXiv","code":""},{"path":"/reference/project.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Project embedding — project","text":"","code":"# get embedding embedding <- embed(neo$text) #> Error in embed(neo$text): No API tokens exist. Set at least one token with set_tokens(). See ?set_tokens  # project embedding project(embedding) #> Error in eval(expr, envir, enclos): object 'embedding' not found"},{"path":"/reference/set_tokens.html","id":null,"dir":"Reference","previous_headings":"","what":"Set API tokens — set_tokens","title":"Set API tokens — set_tokens","text":"set_tokens sets access tokens embedding APIs.","code":""},{"path":"/reference/set_tokens.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set API tokens — set_tokens","text":"","code":"set_tokens(..., hard = FALSE)"},{"path":"/reference/set_tokens.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set API tokens — set_tokens","text":"... one api-token (name-value) pairs (e.g., huggingface = \"TOKEN\"). Names can one c(\"huggingface\",\"openai\",\"cohere\"). hard logical specifying whether tokens overwritten.","code":""},{"path":"/reference/set_tokens.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Set API tokens — set_tokens","text":"function returns matrix containing similarities pairs embedding vectors. matrix nrow(embedding) rows columns.","code":""},{"path":"/reference/set_tokens.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Set API tokens — set_tokens","text":"obtain API tokens users must register respective services: \"Hugging Face\"Sign huggingface.co/inference-api. go profile click settings. Generate access token Access Tokens sub-menu. \"OpenAI\"Sign openai.com/blog/openai-api. Select API. Click Personal (top-right) select View API keys. Create new secret key. \"Cohere\"Sign cohere.com. Select API keys personal dashboard. Either Create Trial key (free charge, rate limited) Create Production key (costly, unlimited). Hugging Face Cohere offer free--charge rate-limited API use.","code":""},{"path":"/reference/set_tokens.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Set API tokens — set_tokens","text":"Wulff, D. U., Aeschbach, S., & Mata, R. (2024). embeddeR. psyArXiv","code":""},{"path":"/reference/set_tokens.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Set API tokens — set_tokens","text":"","code":"# get hugging face token set_tokens(\"huggingface\" = \"TOKEN\")"},{"path":"/reference/text2sdg.html","id":null,"dir":"Reference","previous_headings":"","what":"Embed and analyze text — text2sdg","title":"Embed and analyze text — text2sdg","text":"embedR package provides functions detecting SDGs text, well analyzing visualization hits found text. following provides brief overview contents package.","code":""},{"path":"/reference/text2sdg.html","id":"detect-functions","dir":"Reference","previous_headings":"","what":"Detect functions","title":"Embed and analyze text — text2sdg","text":"detect_sdg detects SDGs text using five different   query systems: Aurora, Elsevier, SIRIS, SDSN, OSDG detect_any detects SDGs text using self-specified queries   utilizing lucene-style syntax   corpustools   package.","code":""},{"path":"/reference/text2sdg.html","id":"analysis-functions","dir":"Reference","previous_headings":"","what":"Analysis functions","title":"Embed and analyze text — text2sdg","text":"plot_sdg visualizes relative frequency SDG hits across   query systems. crosstab_sdg calculates cross tables correlations   either query systems different SDGs.","code":""},{"path":"/reference/text2sdg.html","id":"datasets","dir":"Reference","previous_headings":"","what":"Datasets","title":"Embed and analyze text — text2sdg","text":"projects contain random selection research project   descriptions P3 database Swiss National Science Foundation. aurora_queries, elsevier_queries,   siris_queries, sdsn_queries, auckland_queries   sdgo_queries contain mapping SDGs search queries   employed respective systems.","code":""},{"path":"/reference/text2sdg.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Embed and analyze text — text2sdg","text":"","code":"# \\donttest{ # detect SDGs using default systems hits <- detect_sdg_systems(projects) #> Error in detect_sdg_systems(projects): could not find function \"detect_sdg_systems\"  #' # detect SDGs using all five systems hits <- detect_sdg_systems(projects,   system = c(\"Aurora\", \"Elsevier\", \"SIRIS\", \"SDSN\", \"SDGO\") ) #> Error in detect_sdg_systems(projects, system = c(\"Aurora\", \"Elsevier\",     \"SIRIS\", \"SDSN\", \"SDGO\")): could not find function \"detect_sdg_systems\"  # visualize SDG frequencies plot_sdg(hits) #> Error in plot_sdg(hits): could not find function \"plot_sdg\"  # correlations between systems crosstab_sdg(hits) #> Error in crosstab_sdg(hits): could not find function \"crosstab_sdg\"  # correlations between SDGs crosstab_sdg(hits, compare = \"sdgs\") #> Error in crosstab_sdg(hits, compare = \"sdgs\"): could not find function \"crosstab_sdg\" # }"}]
