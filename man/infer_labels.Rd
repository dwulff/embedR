% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/infer.R
\name{infer_labels}
\alias{infer_labels}
\title{Reduce embedding or projection}
\usage{
infer_labels(
  labels,
  api = "huggingface",
  model = NULL,
  role = "assistant",
  instruct = NULL,
  system = NULL,
  verbose = FALSE
)
}
\arguments{
\item{labels}{a \code{list} of character vectors.}

\item{api}{a \code{character} string specifying the api One of \code{c("huggingface","openai","cohere")}. Default is \code{"openai"}.}

\item{model}{a \code{character} string specifying the model label. Must match the model names on the corresponding APIs. See, \href{https://huggingface.co/models}{huggingface.co/models}, \href{https://platform.openai.com/docs/models/embeddings}{platform.openai.com/docs/models/embeddings}, \href{https://cohere.com/embeddings}{cohere.com/embeddings}. Defaults to \code{"meta-llama/Llama-2-70b-chat-hf"} for \code{api = "huggingface"} and to \code{"gpt-4"} for \code{api = "openai"}.}

\item{role}{a \code{character} string specifying the systems role in place of \code{role} in the general system instruction to the model. Default is \code{"assistant"}.}

\item{instruct}{a \code{character} string specifying the instruction for the model. Must contain the placeholder \code{"{examples}"}. Default is \code{Generate a specific and accurate category label for the following examples: {examples}. Strictly respond with a single word.}.}

\item{system}{a \code{character} string specifying the general system instruction to the model. Default is \code{"You are a helpful and honest \code{role}, who provides specific and accurate category labels based on examples."}.}

\item{verbose}{a \code{logical} specifying whether to show messages.'}
}
\value{
The function returns a \code{character} vector of category labels.
}
\description{
\code{to_tibble} transforms an embedding projections to a tibble ready for \code{ggplot2}.
}
\details{
Note that the default Hugging Face model (meta-llama/Llama-2-70b-chat-hf) requires a PRO subscription token and that extensive of the gpt-4 model can be expensive.
}
\examples{

# get embedding
projection <- embed(neo$text) \%>\%
  project() \%>\%
  to_tibble()

}
\references{
Wulff, D. U., Aeschbach, S., & Mata, R. (2024). embeddeR. psyArXiv
}
